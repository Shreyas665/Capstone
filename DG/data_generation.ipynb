{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "489a3204-3acb-4abb-8b2a-2d98cffb9f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faker\n",
      "  Using cached faker-37.1.0-py3-none-any.whl (1.9 MB)\n",
      "Requirement already satisfied: tzdata in /home/nineleaps/Downloads/jupyter/venv/lib/python3.10/site-packages (from faker) (2025.2)\n",
      "Installing collected packages: faker\n",
      "Successfully installed faker-37.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe755b05-62da-4ac9-b4ca-18fef6a0c478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total generated: 514\n",
      "Productivity data generated successfully.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------\n",
    "# Interrelated HR Data Generation Script (Modified)\n",
    "# -------------------------------------------\n",
    "# This script generates 8 logically interconnected datasets:\n",
    "# 1. Departments\n",
    "# 2. Locations\n",
    "# 3. Leave Types\n",
    "# 4. Job Roles with Role Levels\n",
    "# 5. Employees\n",
    "# 6. Attendance Logs (with surplus/deficit logic)\n",
    "# 7. Leave Records (reduced durations)\n",
    "# 8. Projects (random names)\n",
    "# -------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "from faker import Faker\n",
    "from datetime import datetime, timedelta, time\n",
    "\n",
    "fake = Faker(\"en_IN\")\n",
    "\n",
    "# ----------------------\n",
    "# 1. Departments Table\n",
    "# ----------------------\n",
    "department_names = [\n",
    "    \"Application development\", \"Data\", \"Business development\", \"Experienced Design\",\n",
    "    \"Finance\", \"L&D\", \"Marketing\", \"People Operation\", \"Program Management\",\n",
    "    \"Quality Engineer\", \"Talent Acquisition\", \"Test Engineering and Automation\"\n",
    "]\n",
    "departments_df = pd.DataFrame({\n",
    "    \"department_id\": list(range(1, len(department_names) + 1)),\n",
    "    \"department_name\": department_names\n",
    "})\n",
    "departments_df.to_csv(\"departments.csv\", index=False)\n",
    "\n",
    "# ----------------------\n",
    "# 2. Locations Table\n",
    "# ----------------------\n",
    "location_names = [\"Bangalore\", \"Hyderabad\"]\n",
    "locations_df = pd.DataFrame({\n",
    "    \"location_id\": [1, 2],\n",
    "    \"location_name\": location_names\n",
    "})\n",
    "locations_df.to_csv(\"locations.csv\", index=False)\n",
    "\n",
    "# ----------------------\n",
    "# 3. Leave Types Table\n",
    "# ----------------------\n",
    "leave_types = [\n",
    "    \"Earned Leave\", \"Sick Leave\", \"Family Caregiver Leave\", \"Comp Off Grant\",\n",
    "    \"Bereavement Leave\", \"Loss of Pay (LOP)\"\n",
    "]\n",
    "descriptions = [\n",
    "    \"Accrued monthly, carry forward up to 30 days.\",\n",
    "    \"Used for illness, needs medical certificate beyond 2 days.\",\n",
    "    \"Leave to care for sick family member.\",\n",
    "    \"Compensatory leave granted to employees for working on official holidays or weekly offs\",\n",
    "    \"Leave for death of immediate family.\",\n",
    "    \"Unpaid leave when no paid leave is available.\"\n",
    "]\n",
    "leave_types_df = pd.DataFrame({\n",
    "    \"leave_type_id\": list(range(1, len(leave_types) + 1)),\n",
    "    \"leave_type\": leave_types,\n",
    "    \"description\": descriptions\n",
    "})\n",
    "leave_types_df.to_csv(\"leave_types.csv\", index=False)\n",
    "\n",
    "# ----------------------\n",
    "# 4. Job Roles Table\n",
    "# ----------------------\n",
    "designation_names = [\n",
    "    \"Associate Director - HR\", \"Associate Director - L&D\", \"Associate Director - Programs\", \"Associate Project Manager\",\n",
    "    \"Business Development Executive\", \"Co -Founder CEO\", \"Co-Founder & COO\", \"CTO\", \"Data Analyst I\", \"Data Analyst II\",\n",
    "    \"Data Analyst III\", \"Data Engineering Trainees\", \"DevOps Engineer III\", \"Director - Corporate Finance\",\n",
    "    \"Director - Data Engineering\", \"Director - Sales\", \"Director of Technology\", \"Graphic Designer\",\n",
    "    \"Graduate Engineering Intern\", \"HR Executive\", \"Junior Energy and Sustainability Officer\", \"Intern\",\n",
    "    \"L&D Executive\", \"Lead-Talent Partner\", \"Manager - Marketing\", \"Marketing Executive\", \"Member of Technical Staff II\",\n",
    "    \"Member of Technical Staff III\", \"Office Administrator\", \"Principal Engineer\", \"Project Manager\", \"Quality Engineer I\",\n",
    "    \"Quality Engineer II\", \"Quality Engineer III\", \"Senior Business Analyst\", \"Senior Director Sales\",\n",
    "    \"Senior Manager - Finance\", \"Senior Manager (Data Engineering Operations)\", \"Senior Principal Engineer\",\n",
    "    \"Senior Product Manager\", \"Senior Talent Partner\", \"Senior UI/UX Designer\", \"Software Development Engineer I\",\n",
    "    \"Software Development Engineer II\", \"Software Development Engineer III\", \"Software Development Engineer in Test I\",\n",
    "    \"Software Development Engineer in Test II\", \"Software Development Engineer in Test III\",\n",
    "    \"Software Development Engineer Trainees\", \"Software Engineer II\", \"Talent Partner\", \"Trainee Data Analyst\",\n",
    "    \"Training Data Analyst\", \"UI/UX Designer\", \"Vice President - Data Engineering\"\n",
    "]\n",
    "\n",
    "job_roles_df = pd.DataFrame({\n",
    "    \"designation_id\": list(range(1, len(designation_names) + 1)),\n",
    "    \"designation_name\": designation_names\n",
    "})\n",
    "job_roles_df.to_csv(\"job_roles.csv\", index=False)\n",
    "\n",
    "# ----------------------\n",
    "NUM_EMPLOYEES = 448\n",
    "NUM_INTERNS = 66\n",
    "TOTAL_EMPLOYEES = NUM_EMPLOYEES + NUM_INTERNS  \n",
    "\n",
    "employees = []\n",
    "intern_counter = 1\n",
    "fulltime_counter = 1\n",
    "employment_types = [\"Intern\"] * NUM_INTERNS + [\"Full-Time\"] * NUM_EMPLOYEES\n",
    "random.shuffle(employment_types)\n",
    "\n",
    "def random_dob(min_year, max_year):\n",
    "    start = datetime(min_year, 1, 1)\n",
    "    end = datetime(max_year, 12, 31)\n",
    "    return fake.date_between(start_date=start, end_date=end)\n",
    "\n",
    "def random_join_date():\n",
    "    return fake.date_between(start_date=datetime(2014, 1, 1), end_date=datetime(2024, 12, 31))\n",
    "\n",
    "for i in range(TOTAL_EMPLOYEES):\n",
    "    emp_type = employment_types[i]\n",
    "    \n",
    "    if emp_type == \"Intern\":\n",
    "        employee_id = f\"NLI-{intern_counter:03d}\"\n",
    "        dob = random_dob(2000, 2004)\n",
    "        intern_counter += 1\n",
    "    else:\n",
    "        employee_id = f\"NL-{fulltime_counter:03d}\"\n",
    "        dob = random_dob(1975, 2003)\n",
    "        fulltime_counter += 1\n",
    "\n",
    "    first_name = fake.first_name()\n",
    "    last_name = fake.last_name()\n",
    "    mail_id = f\"{first_name.lower()}{last_name.lower()}@nineleaps.com\"\n",
    "\n",
    "    employees.append({\n",
    "        \"employee_id\": employee_id,\n",
    "        \"first_name\": first_name,\n",
    "        \"last_name\": last_name,\n",
    "        \"full_name\": f\"{first_name} {last_name}\",\n",
    "        \"mail_id\": mail_id,\n",
    "        \"gender\": random.choice([\"Male\", \"Female\"]),\n",
    "        \"dob\": dob,\n",
    "        \"employment_type\": emp_type,\n",
    "        \"department_id\": random.randint(1, len(department_names)),\n",
    "        \"join_date\": random_join_date(),\n",
    "        \"location_id\": random.choice([1, 2])\n",
    "    })\n",
    "\n",
    "employees_df = pd.DataFrame(employees)\n",
    "print(f\"Total generated: {len(employees_df)}\")  # Should print 448\n",
    "employees_df.to_csv(\"employees.csv\", index=False)\n",
    "\n",
    "# ---------\n",
    "# 6. Attendance Logs (With Clea Surplus/Deficit Formatting)\n",
    "# ----------------------\n",
    "attendance_data = []\n",
    "for _, emp in employees_df.iterrows():\n",
    "    join_date = pd.to_datetime(emp['join_date'])\n",
    "    for day in pd.date_range(start=max(join_date, datetime(2024, 3, 1)), end=datetime(2025, 3, 31)):\n",
    "        if day.weekday() < 5 and random.random() > 0.1:\n",
    "            is_half_day = random.random() < 0.1\n",
    "            if is_half_day:\n",
    "                check_in_hour = random.randint(13, 14)\n",
    "                duration_minutes = random.randint(180, 240)\n",
    "            else:\n",
    "                check_in_hour = random.randint(8, 10)\n",
    "                duration_minutes = random.randint(510, 570)  # Around 9 hrs\n",
    "\n",
    "            check_in = datetime.combine(day, time(hour=check_in_hour, minute=random.choice([0, 15, 30, 45])))\n",
    "            check_out = check_in + timedelta(minutes=duration_minutes)\n",
    "            working_hours = f\"{duration_minutes // 60}hr {duration_minutes % 60}min\"\n",
    "\n",
    "            def format_time(minutes):\n",
    "                hours = minutes // 60\n",
    "                mins = minutes % 60\n",
    "                if hours == 0:\n",
    "                    return f\"{mins}min\"\n",
    "                elif mins == 0:\n",
    "                    return f\"{hours}hr\"\n",
    "                else:\n",
    "                    return f\"{hours}hr {mins}min\"\n",
    "\n",
    "            if duration_minutes < 540:\n",
    "                surplus = None\n",
    "                deficit = format_time(540 - duration_minutes)\n",
    "            else:\n",
    "                deficit = None\n",
    "                surplus = format_time(duration_minutes - 540)\n",
    "\n",
    "            attendance_data.append({\n",
    "                \"employee_id\": emp['employee_id'],\n",
    "                \"date\": day.date(),\n",
    "                \"check_in\": check_in.time(),\n",
    "                \"check_out\": check_out.time(),\n",
    "                \"working_hours\": working_hours,\n",
    "                \"surplus\": surplus,\n",
    "                \"deficit\": deficit,\n",
    "                \"is_half_day\": is_half_day\n",
    "            })\n",
    "\n",
    "attendance_df = pd.DataFrame(attendance_data)\n",
    "attendance_df.to_csv(\"attendance_logs.csv\", index=False)\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# 7. Leave Records (Reduced Durations)\n",
    "# ----------------------\n",
    "leave_data = []\n",
    "leave_type_dict = {1: \"Earned Leave\", 2: \"Sick Leave\", 3: \"Family Caregiver Leave\", 4: \"Bereavement Leave\", 5: \"Loss of Pay (LOP)\"}\n",
    "for _, emp in employees_df.iterrows():\n",
    "    join = pd.to_datetime(emp['join_date'])\n",
    "    if join > datetime(2025, 1, 1):\n",
    "        continue\n",
    "\n",
    "    for leave_type_id, leave_type in leave_type_dict.items():\n",
    "        if leave_type == \"Sick Leave\" and random.random() < 0.4:\n",
    "            start = join + timedelta(days=random.randint(30, 240))\n",
    "            leave_data.append({\n",
    "                \"employee_id\": emp['employee_id'],\n",
    "                \"leave_type_id\": leave_type_id,\n",
    "                \"start_date\": start.date(),\n",
    "                \"end_date\": (start + timedelta(days=3)).date(),\n",
    "                \"duration\": 4,\n",
    "                \"reason\": \"Medical - Flu\"\n",
    "            })\n",
    "\n",
    "        elif leave_type == \"Earned Leave\":\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                days = random.randint(2, 4)\n",
    "                start = join + timedelta(days=random.randint(30, 300))\n",
    "                leave_data.append({\n",
    "                    \"employee_id\": emp['employee_id'],\n",
    "                    \"leave_type_id\": leave_type_id,\n",
    "                    \"start_date\": start.date(),\n",
    "                    \"end_date\": (start + timedelta(days=days - 1)).date(),\n",
    "                    \"duration\": days,\n",
    "                    \"reason\": \"Vacation\"\n",
    "                })\n",
    "\n",
    "        elif leave_type == \"Bereavement Leave\" and random.random() < 0.1:\n",
    "            days = random.randint(2, 4)\n",
    "            start = join + timedelta(days=random.randint(60, 300))\n",
    "            leave_data.append({\n",
    "                \"employee_id\": emp['employee_id'],\n",
    "                \"leave_type_id\": leave_type_id,\n",
    "                \"start_date\": start.date(),\n",
    "                \"end_date\": (start + timedelta(days=days - 1)).date(),\n",
    "                \"duration\": days,\n",
    "                \"reason\": \"Family bereavement\"\n",
    "            })\n",
    "\n",
    "        elif leave_type == \"Family Caregiver Leave\" and random.random() < 0.15:\n",
    "            days = random.randint(2, 6)\n",
    "            start = join + timedelta(days=random.randint(90, 330))\n",
    "            leave_data.append({\n",
    "                \"employee_id\": emp['employee_id'],\n",
    "                \"leave_type_id\": leave_type_id,\n",
    "                \"start_date\": start.date(),\n",
    "                \"end_date\": (start + timedelta(days=days - 1)).date(),\n",
    "                \"duration\": days,\n",
    "                \"reason\": \"Care for family\"\n",
    "            })\n",
    "\n",
    "        elif leave_type == \"Loss of Pay (LOP)\" and random.random() < 0.1:\n",
    "            days = random.randint(1, 2)\n",
    "            start = join + timedelta(days=random.randint(20, 280))\n",
    "            leave_data.append({\n",
    "                \"employee_id\": emp['employee_id'],\n",
    "                \"leave_type_id\": leave_type_id,\n",
    "                \"start_date\": start.date(),\n",
    "                \"end_date\": (start + timedelta(days=days - 1)).date(),\n",
    "                \"duration\": days,\n",
    "                \"reason\": \"LOP\"\n",
    "            })\n",
    "\n",
    "leave_df = pd.DataFrame(leave_data)\n",
    "leave_df.to_csv(\"leave_records.csv\", index=False)\n",
    "\n",
    "# ----------------------\n",
    "# 8. Projects Table (with Realistic Unique Names, No Suffixes)\n",
    "# ----------------------\n",
    "project_names_pool = [\n",
    "    \"Orion\", \"Nova\", \"Athena\", \"Pulse\", \"Nimbus\", \"Fusion\", \"Spectra\", \"Helix\", \"Zenith\", \"Vertex\",\n",
    "    \"Apollo\", \"Horizon\", \"Equinox\", \"Eclipse\", \"Velocity\", \"Ignite\", \"Quantum\", \"Catalyst\", \"Sierra\", \"Omega\"\n",
    "]\n",
    "\n",
    "# Sample 30 unique project names from the pool\n",
    "unique_project_names = random.sample(project_names_pool * 2, 30)\n",
    "\n",
    "project_data = []\n",
    "for pid in range(1, 31):\n",
    "    project_name = unique_project_names[pid - 1]  # Use clean unique name\n",
    "    tech_stack = random.choice([\"Python\", \"Java\", \"Node.js\", \"React\", \"Data Engineering\", \"DevOps\"])\n",
    "    lead = employees_df[employees_df['employment_type'] == 'Full-Time'].sample(1).iloc[0]['employee_id']\n",
    "    assigned = employees_df.sample(random.randint(5, 12))['employee_id'].tolist()\n",
    "    for emp_id in assigned:\n",
    "        project_data.append({\n",
    "            \"project_id\": pid,\n",
    "            \"project_name\": project_name,\n",
    "            \"tech_stack\": tech_stack,\n",
    "            \"employee_id\": emp_id,\n",
    "            \"lead_id\": lead\n",
    "        })\n",
    "\n",
    "projects_df = pd.DataFrame(project_data)\n",
    "projects_df.to_csv(\"projects.csv\", index=False)\n",
    "\n",
    "#\n",
    "# 9. Productivity Table\n",
    "# ----------------------\n",
    "productivity_data = []\n",
    "for _, emp in employees_df.iterrows():\n",
    "    employee_id = emp['employee_id']\n",
    "    \n",
    "    # Randomly assign a project to the employee\n",
    "    assigned_projects = projects_df[projects_df['employee_id'] == employee_id]['project_id'].unique()\n",
    "    \n",
    "    # If no project assigned, skip this employee\n",
    "    if not assigned_projects.any():\n",
    "        continue\n",
    "    \n",
    "    project_id = random.choice(assigned_projects)\n",
    "    \n",
    "    # Generate random productivity data for each employee (let's assume we want daily records for 1 month)\n",
    "    for day in pd.date_range(start=datetime(2024, 3, 1), end=datetime(2025, 3, 31), freq='MS'):\n",
    "        # Skip weekends (Saturday and Sunday)\n",
    "        if day.weekday() >= 5:\n",
    "            continue\n",
    "        \n",
    "        tasks_assigned = random.randint(3, 10)  # Random tasks assigned between 3 and 10\n",
    "        tasks_completed = random.randint(2, tasks_assigned)  # Tasks completed are between 0 and tasks assigned\n",
    "        task_quality_score = round(random.uniform(0.0, 5.0), 2)  # Random task quality score between 0 and 5\n",
    "        \n",
    "        # Calculate productivity score\n",
    "        if tasks_assigned > 0:\n",
    "            productivity_score = (tasks_completed / tasks_assigned) * task_quality_score\n",
    "        else:\n",
    "            productivity_score = 0\n",
    "        \n",
    "        productivity_score = round(productivity_score, 2)\n",
    "\n",
    "        # Assign meaningful remarks based on productivity_score\n",
    "        if productivity_score >= 4.0:\n",
    "            remarks = \"Outstanding Contributor\"\n",
    "        elif productivity_score >= 3.0:\n",
    "            remarks = \"Consistently Effective\"\n",
    "        elif productivity_score >= 2.0:\n",
    "            remarks = \"Needs Closer Monitoring\"\n",
    "        elif productivity_score >= 1.0:\n",
    "            remarks = \"Performance Improvement Plan\"\n",
    "        else:\n",
    "            remarks = \"Critical Underperformance\"\n",
    "        \n",
    "        productivity_data.append({\n",
    "            \"employee_id\": employee_id,\n",
    "            \"project_id\": project_id,\n",
    "            \"assigned_date\": day.date(),\n",
    "            \"tasks_assigned\": tasks_assigned,\n",
    "            \"tasks_completed\": tasks_completed,\n",
    "            \"task_quality_score\": task_quality_score,\n",
    "            \"productivity_score\": productivity_score,\n",
    "            \"remarks\": remarks\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "productivity_df = pd.DataFrame(productivity_data)\n",
    "\n",
    "# Save to CSV\n",
    "productivity_df.to_csv(\"productivity.csv\", index=False)\n",
    "\n",
    "print(\"Productivity data generated successfully.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
